{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "madwwsmqApxd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras import layers, models\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Conv1D\n",
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "from collections import deque, Counter\n",
        "import random\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataReader:\n",
        "\n",
        "    def __init__(self, ticker = 'SPY', start_date = '2010-03-03', end_date = '2023-01-01'):\n",
        "\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "\n",
        "        self.data = yf.download(ticker, start_date, end_date)\n",
        "        self.data.dropna(axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.data\n",
        "\n",
        "    def get_dates(self):\n",
        "        return {'start_date': self.start_date, 'end_date': self.end_date}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JiO-LaNNB51o"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "\n",
        "    def __init__(self, state_size, testing_mode = False, model_name = \"\"):\n",
        "\n",
        "        self.state_size = state_size\n",
        "        self.states_dict = Counter(['Buy','Sell','Hold'])\n",
        "        self.action_size =3\n",
        "        self.testing_mode = testing_mode #True if the testing has been initiated\n",
        "        self.replay_memory = deque(maxlen = 1000)\n",
        "        self.model_name = model_name\n",
        "        self.inventory = []\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.99\n",
        "\n",
        "\n",
        "        if self.testing_mode:\n",
        "            self.model = load_model(model_name)\n",
        "        else:\n",
        "            self.model = self.build_model()\n",
        "\n",
        "    def build_model(self, hidden_dim=64):\n",
        "\n",
        "        model = Sequential([\n",
        "            Dense(hidden_dim, input_dim = self.state_size, activation = 'relu'),\n",
        "            Dense(hidden_dim//2, activation = 'relu'),\n",
        "            Dense(hidden_dim//4, activation = 'relu'),\n",
        "            Dense(self.action_size, activation = 'linear')\n",
        "        ])\n",
        "\n",
        "        self.compile_model(model)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def compile_model(self, model, lr = 0.001):\n",
        "        opt = Adam(lr = lr)\n",
        "        model.compile(loss ='mae', optimizer = opt)\n",
        "        return\n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\" epsilon_greedy approach\"\"\"\n",
        "        if self.testing_mode == False:\n",
        "            if random.random() <= self.epsilon:\n",
        "                return random.randrange(self.action_size)\n",
        "\n",
        "        next_states = self.model.predict(state)\n",
        "\n",
        "        return np.argmax(next_states[0])\n",
        "\n",
        "    def experience_replay(self, batch_size):\n",
        "        l = len(self.replay_memory)\n",
        "        mini_batch = self.replay_memory[l - batch_size+1: l]\n",
        "\n",
        "        for state, action, reward, next_state, done in mini_batch:\n",
        "            target = reward\n",
        "            if done == False:\n",
        "\n",
        "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
        "\n",
        "\n",
        "            target_f = self.model.predict(state)\n",
        "\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state, target_f, epochs = 1, verbose = 0)\n",
        "\n",
        "\n",
        "            if self.epsilon >  self.epsilon_min:\n",
        "                self.epsilon *= self.epsilon_decay\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UzaBz6YqGnG3"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HelperFuncs:\n",
        "\n",
        "    def __init__(self, data):\n",
        "\n",
        "        self.data = data\n",
        "    def price_string (self, n):\n",
        "\n",
        "        sgn = \"\"\n",
        "        if n<0 : sgn+=\"-\"\n",
        "\n",
        "        return sgn + \"$\" + \"{0:.2f}\".format(abs(n))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1/(1+math.exp(x))\n",
        "\n",
        "\n",
        "    def get_states(self, t,n):\n",
        "\n",
        "        d = t - n + 1\n",
        "\n",
        "        if d >= 0:\n",
        "            block = self.data[d:t+1]\n",
        "\n",
        "        else:\n",
        "            block = -d * [self.data[0]] + self.data[0:t+1]\n",
        "\n",
        "        res = block[1:] - block[:-1]\n",
        "\n",
        "        return res"
      ],
      "metadata": {
        "id": "UeCTvO6reNhi"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Training:\n",
        "\n",
        "    def __init__(self,data,splitting_size = 0.8):\n",
        "\n",
        "        self.data = data\n",
        "        self.agent = None\n",
        "        self.splitting_size = splitting_size\n",
        "\n",
        "        self.training_data, self.validating_data = self.train_test_split(self.data,self.splitting_size)\n",
        "\n",
        "    def train_test_split (self, data, splitting_size):\n",
        "\n",
        "        split_at = (int)(len(data) * splitting_size)\n",
        "\n",
        "        return data[ : split_at], data[split_at : ]\n",
        "\n",
        "\n",
        "\n",
        "    def train_agent(self,  batch_size = 32, ep_count = 10):\n",
        "        window_size = 1\n",
        "        self.agent = Agent(window_size)\n",
        "\n",
        "        data = self.training_data\n",
        "        l = len(data)-1\n",
        "        helper = HelperFuncs(self.training_data)\n",
        "        for ep in range(ep_count + 1):\n",
        "\n",
        "            print(f'Episode {str(ep)}/{str(ep+1)}:')\n",
        "            state = helper.get_states(0, window_size + 1)\n",
        "            total_profit = 0\n",
        "            self.agent.replay_memory = []\n",
        "            states_sell = []\n",
        "            states_buy = []\n",
        "\n",
        "            for t in range(l):\n",
        "                print(t,l)\n",
        "                action = self.agent.act(state)\n",
        "                next_state = helper.get_states( t + 1, window_size + 1)\n",
        "                reward = 0\n",
        "\n",
        "                if self.agent.states_dict[action] == 'Buy':\n",
        "\n",
        "                    self.agent.inventory.append(data[t])\n",
        "                    states_buy.append(t)\n",
        "\n",
        "                elif self.agent.states_dict[action] == 'Sell':\n",
        "\n",
        "                    bought_price = self.agent.inventory.pop(0)\n",
        "                    reward = max(data[t] - bought_price, 0 )\n",
        "                    total_profit += data[t] - bought_price\n",
        "                    states_sell.append(t)\n",
        "                done = t== l - 1\n",
        "                self.agent.replay_memory.append((state, action, reward, next_state, done))\n",
        "                state = next_state\n",
        "                if done:\n",
        "                    print(\"--------------------------------\")\n",
        "                    print(\"Total Profit: \" + helper.price_string(total_profit))\n",
        "                    print(\"--------------------------------\")\n",
        "\n",
        "                    helper.plot(data,states_buy, states_sell, total_profit)\n",
        "                if len(self.agent.replay_memory) > batch_size:\n",
        "                    self.agent.experience_replay(batch_size)\n",
        "            if ep % 2 == 0:\n",
        "\n",
        "                self.agent.model.save('model_ep' + str(ep))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "pe2fHAVBlpLn"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = DataReader()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKVlCIKhqh9I",
        "outputId": "2a86dd1a-d903-40fa-863d-d57e41f330c7"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(reader.get_data()['Close'])\n",
        "train = Training(data)\n",
        "train.train_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GuaWXuHr9G4",
        "outputId": "dd0f78b0-290a-4925-d922-8541b43ca5bb"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([112.30000305, 112.63999939, 114.25      , ..., 376.66000366,\n",
              "       383.44000244, 382.42999268])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X9HE1s-B3F9_"
      }
    }
  ]
}