{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from helper import *\n",
        "from Agent import *\n",
        "from reader import *\n",
        "\n",
        "import keras\n",
        "from keras import layers, models, optimizers\n",
        "from keras import backend as K\n",
        "from collections import namedtuple, deque\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import read_csv, set_option import datetime\n",
        "import math\n",
        "from numpy.random import choice\n",
        "import random\n",
        "from collections import deque"
      ],
      "metadata": {
        "id": "r95U63hJkPi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Train():\n",
        "\n",
        "    def __init__(self, window_size = 1, batch_size = 32, split_size = 0.8,\n",
        "                ep_count = 10):\n",
        "        reader = DataReader()\n",
        "        reader.read_data()\n",
        "        self.data = np.array(reader.get_data())\n",
        "        self.train_data = []\n",
        "        self.validation_data = []\n",
        "        self.window_size = window_size\n",
        "        self.batch_size = batch_size\n",
        "        self.split_size = split_size\n",
        "        self.agent = Trading_Agent(self.window_size)\n",
        "        self.ep_count = ep_count\n",
        "    def train_test_split(self):\n",
        "\n",
        "        split_at = (int) (self.split_size * len(self.data))\n",
        "        training_data = self.data[:split_at]\n",
        "        validating_data = self.data[split_at:]\n",
        "        return training_data, validating_data\n",
        "\n",
        "    def train_DQN(self, training_data):\n",
        "        helper = Helper(training_data)\n",
        "        l = len(training_data)-1\n",
        "        for ep in range(self.ep_count + 1):\n",
        "          print(f'Running episode {ep}/{self.ep_count}')\n",
        "          state = helper.get_states(0, self.window_size + 1)\n",
        "          total_profit = 0\n",
        "          self.agent.inventory = []\n",
        "          states_sells = []\n",
        "          states_buys = []\n",
        "\n",
        "          for t in range(l):\n",
        "\n",
        "            action = self.agent.act(state)\n",
        "            next_state = helper.get_states(t+1, self.window_size +1 )\n",
        "            reward = 0\n",
        "\n",
        "          if self.agent.actions_dict[action] == 'Buy':\n",
        "            self.agent.inventory.append(data[t])\n",
        "            self.states_buy.append(t)\n",
        "\n",
        "          elif action == 2 and len(agent.inventory) > 0 :\n",
        "\n",
        "            bought_price = self.agent.inventory.pop()\n",
        "            reward = max(self.data[t] - bought_price, 0)\n",
        "            total_profit += self.data[t] - bought_price\n",
        "            self.state_sells.append(t)\n",
        "\n",
        "          done = True if t == l-1 else False\n",
        "\n",
        "          self.agent.memory.append((state,action,reward, next_state, done))\n",
        "\n",
        "          state = next_state\n",
        "\n",
        "\n",
        "        if done:\n",
        "            print(\"--------------------------------\")\n",
        "            print(\"Total Profit: \" + formatPrice(total_profit))\n",
        "            print(\"--------------------------------\")\n",
        "            #set_trace()\n",
        "            #pd.DataFrame(np.array(agent.memory)).to_csv(\"Agent\"+str(e)+\".csv\")\n",
        "            #Chart to show how the model performs with the stock goin up and down for each\n",
        "            helper.plot_behavior(self.data,states_buys, states_sells, total_profit)\n",
        "        if len(self.agent.memory) > self.batch_size:\n",
        "            self.agent.expReplay(self.batch_size)\n",
        "\n",
        "\n",
        "        if e % 2 == 0:\n",
        "          self.agent.model.save('model_ep' + str(ep))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qKAHMyNu7ZXW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}